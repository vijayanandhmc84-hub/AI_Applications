# Production Environment Variables Template
# Copy this file to .env.production and fill in your values

# ==========================================
# DATABASE CONFIGURATION
# ==========================================
# PostgreSQL connection string
# Format: postgresql://user:password@host:port/database
DATABASE_URL=postgresql://user:password@your-postgres-host:5432/docuchat

# ==========================================
# LLM PROVIDER CONFIGURATION
# ==========================================
# Choose one: ollama, openai, groq, gemini
LLM_PROVIDER=openai

# For OpenAI (recommended for production)
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# For Ollama (not recommended for production - requires server)
# OLLAMA_BASE_URL=https://your-ollama-server.com
# OLLAMA_MODEL=llama3.2

# For Groq (fast, free tier available)
# GROQ_API_KEY=your-groq-api-key
# GROQ_MODEL=llama-3.1-8b-instant

# For Google Gemini (free tier available)
# GOOGLE_API_KEY=your-gemini-api-key

# ==========================================
# EMBEDDING MODEL
# ==========================================
EMBEDDING_MODEL=all-MiniLM-L6-v2
# For production, consider: text-embedding-3-small (OpenAI)

# ==========================================
# APPLICATION SETTINGS
# ==========================================
# Directory for file uploads (absolute path or relative to backend/)
UPLOAD_DIR=/app/uploads

# Maximum file size in bytes (50MB default)
MAX_FILE_SIZE=52428800

# Chunk settings for text splitting
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# Vector search settings
TOP_K_RESULTS=5

# ==========================================
# CORS SETTINGS
# ==========================================
# Comma-separated list of allowed origins
ALLOWED_ORIGINS=https://your-frontend-domain.com,https://www.your-frontend-domain.com

# ==========================================
# REDIS (Optional - for caching)
# ==========================================
# REDIS_URL=redis://default:password@redis-host:6379/0

# ==========================================
# MONITORING & LOGGING
# ==========================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Sentry DSN for error tracking (optional)
# SENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id

# ==========================================
# SECURITY
# ==========================================
# Secret key for JWT tokens (generate with: openssl rand -hex 32)
SECRET_KEY=your-secret-key-here-generate-with-openssl-rand-hex-32

# JWT expiration time in minutes
JWT_EXPIRATION_MINUTES=1440

# ==========================================
# PERFORMANCE
# ==========================================
# Number of worker processes for Uvicorn
WORKERS=4

# Timeout for LLM requests in seconds
LLM_TIMEOUT=180

# ==========================================
# FRONTEND ENVIRONMENT VARIABLES
# ==========================================
# Backend API URL (for Next.js frontend)
NEXT_PUBLIC_API_URL=https://your-backend-api.com
