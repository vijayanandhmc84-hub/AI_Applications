# Deployment Guide

This guide covers deploying the Multimodal Document Chat System to various platforms.

## Table of Contents

1. [Railway Deployment](#railway-deployment)
2. [Vercel + Railway Deployment](#vercel--railway-deployment)
3. [Docker Production Deployment](#docker-production-deployment)
4. [AWS Deployment](#aws-deployment)
5. [Environment Variables](#environment-variables)
6. [Post-Deployment Steps](#post-deployment-steps)

---

## Railway Deployment

Railway is the easiest way to deploy the backend with PostgreSQL included.

### Prerequisites
- Railway account (https://railway.app)
- GitHub account
- OpenAI API key or other LLM provider

### Step 1: Create Railway Project

1. Go to https://railway.app and sign in
2. Click "New Project"
3. Select "Deploy from GitHub repo"
4. Connect your GitHub account and select this repository

### Step 2: Add PostgreSQL Database

1. In your Railway project, click "New"
2. Select "Database" → "PostgreSQL"
3. Railway will automatically create a PostgreSQL instance with pgvector

### Step 3: Configure Backend Service

1. Click on your backend service
2. Go to "Variables" tab
3. Add the following environment variables:

```bash
# Database (auto-generated by Railway)
DATABASE_URL=${{Postgres.DATABASE_URL}}

# LLM Provider
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Application Settings
UPLOAD_DIR=/app/uploads
MAX_FILE_SIZE=52428800
CHUNK_SIZE=500
CHUNK_OVERLAP=50
TOP_K_RESULTS=5
LOG_LEVEL=INFO

# CORS (update with your frontend domain)
ALLOWED_ORIGINS=https://your-frontend.vercel.app
```

4. Go to "Settings" tab
5. Set "Start Command": `cd backend && uvicorn app.main:app --host 0.0.0.0 --port $PORT`
6. Set "Root Directory": `/` (or leave empty)

### Step 4: Enable pgvector Extension

1. Click on your PostgreSQL database
2. Go to "Connect" → "Postgres Connection URL"
3. Use a PostgreSQL client to connect and run:

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

Or use Railway's built-in query editor.

### Step 5: Deploy

1. Railway will automatically deploy on every git push
2. Wait for deployment to complete (check logs)
3. Copy your backend URL from Railway dashboard

### Expected Result

- Backend API: `https://your-app.railway.app`
- API Docs: `https://your-app.railway.app/docs`
- Health Check: `https://your-app.railway.app/health`

---

## Vercel + Railway Deployment

Deploy frontend on Vercel, backend on Railway.

### Step 1: Deploy Backend on Railway

Follow the [Railway Deployment](#railway-deployment) steps above.

### Step 2: Deploy Frontend on Vercel

1. Go to https://vercel.com and sign in
2. Click "New Project"
3. Import your GitHub repository
4. Configure project:
   - **Framework Preset**: Next.js
   - **Root Directory**: `frontend`
   - **Build Command**: `npm run build`
   - **Output Directory**: `.next`

5. Add environment variable:
   ```
   NEXT_PUBLIC_API_URL=https://your-backend.railway.app
   ```

6. Click "Deploy"

### Step 3: Update CORS on Backend

1. Go to Railway project
2. Update `ALLOWED_ORIGINS` variable:
   ```
   ALLOWED_ORIGINS=https://your-app.vercel.app,https://your-app-*.vercel.app
   ```

### Expected Result

- Frontend: `https://your-app.vercel.app`
- Backend: `https://your-backend.railway.app`

---

## Docker Production Deployment

Deploy using Docker Compose with Nginx reverse proxy.

### Prerequisites
- Linux server (Ubuntu 20.04+ recommended)
- Docker and Docker Compose installed
- Domain name pointing to your server
- SSL certificate (Let's Encrypt recommended)

### Step 1: Clone Repository

```bash
git clone <your-repo-url>
cd coding-test-4h-main
```

### Step 2: Configure Environment

```bash
# Copy production environment template
cp .env.production.example .env.production

# Edit with your values
nano .env.production
```

Required variables:
```bash
# Database
POSTGRES_USER=docuser
POSTGRES_PASSWORD=your-secure-password-here
POSTGRES_DB=docdb

# LLM
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here

# CORS
ALLOWED_ORIGINS=https://yourdomain.com

# Frontend
NEXT_PUBLIC_API_URL=https://api.yourdomain.com
```

### Step 3: Setup SSL Certificates

Option A: Let's Encrypt (Recommended)

```bash
# Install certbot
sudo apt-get update
sudo apt-get install certbot

# Generate certificate
sudo certbot certonly --standalone -d yourdomain.com -d api.yourdomain.com

# Copy certificates to nginx directory
sudo cp /etc/letsencrypt/live/yourdomain.com/fullchain.pem nginx/ssl/cert.pem
sudo cp /etc/letsencrypt/live/yourdomain.com/privkey.pem nginx/ssl/key.pem
```

Option B: Self-signed (Development only)

```bash
mkdir -p nginx/ssl
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout nginx/ssl/key.pem \
  -out nginx/ssl/cert.pem
```

### Step 4: Update Nginx Configuration

Edit `nginx/nginx.conf` and update `server_name`:

```nginx
server_name yourdomain.com www.yourdomain.com;
```

### Step 5: Deploy with Docker Compose

```bash
# Build and start services
docker-compose -f docker-compose.prod.yml up -d

# Check logs
docker-compose -f docker-compose.prod.yml logs -f

# Verify all services are running
docker-compose -f docker-compose.prod.yml ps
```

### Step 6: Initialize Database

```bash
# Connect to PostgreSQL
docker exec -it postgres_prod psql -U docuser -d docdb

# Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

# Exit
\q
```

### Step 7: Setup Auto-renewal for SSL (Let's Encrypt)

```bash
# Add cron job for certificate renewal
sudo crontab -e

# Add this line (renew certificate every 3 months)
0 3 1 */3 * certbot renew --quiet && docker-compose -f /path/to/docker-compose.prod.yml restart nginx
```

### Expected Result

- Frontend: `https://yourdomain.com`
- Backend API: `https://yourdomain.com/api`
- API Docs: `https://yourdomain.com/docs`

---

## AWS Deployment

Deploy using AWS services (ECS, RDS, S3).

### Architecture

```
Internet → ALB → ECS (Backend) → RDS PostgreSQL
              ↓
           S3 (File Storage)
              ↓
       CloudFront (Frontend)
```

### Step 1: Setup RDS PostgreSQL

1. Go to AWS RDS Console
2. Create database:
   - **Engine**: PostgreSQL 15
   - **Template**: Production
   - **Instance**: db.t3.medium (or larger)
   - **Storage**: 100 GB SSD
   - **Enable**: Multi-AZ, Automated backups

3. Enable pgvector:
   ```sql
   CREATE EXTENSION IF NOT EXISTS vector;
   ```

### Step 2: Setup S3 Bucket

1. Create S3 bucket: `your-app-uploads`
2. Enable versioning
3. Setup CORS:
   ```json
   [
     {
       "AllowedHeaders": ["*"],
       "AllowedMethods": ["GET", "PUT", "POST"],
       "AllowedOrigins": ["https://yourdomain.com"],
       "ExposeHeaders": []
     }
   ]
   ```

### Step 3: Deploy Backend on ECS

1. Build and push Docker image to ECR:
   ```bash
   aws ecr create-repository --repository-name docuchat-backend
   docker build -f backend/Dockerfile.prod -t docuchat-backend .
   docker tag docuchat-backend:latest <account-id>.dkr.ecr.region.amazonaws.com/docuchat-backend:latest
   docker push <account-id>.dkr.ecr.region.amazonaws.com/docuchat-backend:latest
   ```

2. Create ECS Task Definition with environment variables
3. Create ECS Service with ALB
4. Configure Auto Scaling (min: 2, max: 10 tasks)

### Step 4: Deploy Frontend on CloudFront + S3

1. Build frontend:
   ```bash
   cd frontend
   NEXT_PUBLIC_API_URL=https://api.yourdomain.com npm run build
   npm run export
   ```

2. Upload to S3:
   ```bash
   aws s3 sync out/ s3://your-frontend-bucket/
   ```

3. Create CloudFront distribution pointing to S3 bucket

### Step 5: Configure Route53

1. Create hosted zone for your domain
2. Add A record for `api.yourdomain.com` → ALB
3. Add A record for `yourdomain.com` → CloudFront

---

## Environment Variables

### Backend Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `DATABASE_URL` | Yes | - | PostgreSQL connection string |
| `LLM_PROVIDER` | Yes | `openai` | LLM provider (openai, ollama, groq, gemini) |
| `OPENAI_API_KEY` | Conditional | - | Required if using OpenAI |
| `OPENAI_MODEL` | No | `gpt-4o-mini` | OpenAI model name |
| `OPENAI_EMBEDDING_MODEL` | No | `text-embedding-3-small` | Embedding model |
| `UPLOAD_DIR` | No | `/app/uploads` | Upload directory path |
| `MAX_FILE_SIZE` | No | `52428800` | Max file size in bytes (50MB) |
| `CHUNK_SIZE` | No | `500` | Text chunk size |
| `CHUNK_OVERLAP` | No | `50` | Text chunk overlap |
| `TOP_K_RESULTS` | No | `5` | Number of search results |
| `ALLOWED_ORIGINS` | No | `*` | CORS allowed origins |
| `LOG_LEVEL` | No | `INFO` | Logging level |
| `WORKERS` | No | `4` | Uvicorn worker processes |

### Frontend Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `NEXT_PUBLIC_API_URL` | Yes | - | Backend API URL |
| `NODE_ENV` | No | `production` | Node environment |

---

## Post-Deployment Steps

### 1. Verify Deployment

```bash
# Check backend health
curl https://your-backend-url/health

# Check API documentation
open https://your-backend-url/docs

# Test file upload
curl -X POST "https://your-backend-url/api/documents/upload" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@sample.pdf"
```

### 2. Setup Monitoring

#### Option A: Sentry (Error Tracking)

1. Create Sentry project at https://sentry.io
2. Add to environment variables:
   ```bash
   SENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id
   ```

#### Option B: CloudWatch (AWS)

1. Enable CloudWatch Logs for ECS tasks
2. Create alarms for:
   - High error rate
   - High CPU usage
   - High memory usage

### 3. Setup Backups

#### Database Backups

**Railway**: Automatic daily backups included

**AWS RDS**:
```bash
# Enable automated backups (7-day retention)
aws rds modify-db-instance \
  --db-instance-identifier your-db \
  --backup-retention-period 7
```

**Docker**:
```bash
# Create backup script
cat > backup-db.sh << 'EOF'
#!/bin/bash
docker exec postgres_prod pg_dump -U docuser docdb > backup-$(date +%Y%m%d).sql
EOF

# Add to crontab (daily at 2 AM)
0 2 * * * /path/to/backup-db.sh
```

#### File Storage Backups

**S3**: Enable versioning and lifecycle policies

**Local**:
```bash
# Sync uploads to S3
aws s3 sync /app/uploads s3://your-backup-bucket/uploads/
```

### 4. Performance Optimization

1. **Enable Redis caching**:
   ```bash
   REDIS_URL=redis://your-redis-host:6379/0
   ```

2. **Add CDN for static files**:
   - CloudFront (AWS)
   - CloudFlare
   - Vercel Edge Network

3. **Database indexing**:
   ```sql
   CREATE INDEX idx_chunks_embedding ON document_chunks
   USING ivfflat (embedding vector_cosine_ops)
   WITH (lists = 100);
   ```

### 5. Security Hardening

1. **Enable rate limiting** (already configured in Nginx)
2. **Setup WAF** (AWS WAF or CloudFlare)
3. **Enable DDoS protection**
4. **Regular security updates**:
   ```bash
   # Update Docker images
   docker-compose -f docker-compose.prod.yml pull
   docker-compose -f docker-compose.prod.yml up -d
   ```

### 6. Monitoring Dashboard

Setup Grafana + Prometheus:

```bash
# Add monitoring services to docker-compose.prod.yml
services:
  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
```

---

## Troubleshooting

### Common Issues

**1. Database connection fails**
```bash
# Check DATABASE_URL format
postgresql://user:password@host:port/database

# Verify network connectivity
docker exec backend_prod ping postgres

# Check PostgreSQL logs
docker-compose -f docker-compose.prod.yml logs postgres
```

**2. File uploads fail**
```bash
# Check upload directory permissions
docker exec backend_prod ls -la /app/uploads

# Verify MAX_FILE_SIZE setting
docker exec backend_prod env | grep MAX_FILE_SIZE
```

**3. LLM timeouts**
```bash
# Increase timeout in environment
LLM_TIMEOUT=300

# Check LLM provider status
curl https://api.openai.com/v1/models
```

**4. Out of memory**
```bash
# Increase container memory limit
docker-compose -f docker-compose.prod.yml up -d \
  --scale backend=2 \
  --memory=4g
```

---

## Cost Estimation

### Railway (Recommended for MVP)

- **Database**: $5-10/month (shared PostgreSQL)
- **Backend**: $5-20/month (based on usage)
- **Total**: $10-30/month

### Vercel + Railway

- **Vercel Frontend**: Free (hobby plan)
- **Railway Backend**: $10-30/month
- **Total**: $10-30/month

### AWS (Production Scale)

- **RDS PostgreSQL**: $50-200/month (db.t3.medium)
- **ECS**: $30-100/month (2-4 tasks)
- **S3**: $5-20/month (storage + bandwidth)
- **ALB**: $20/month
- **CloudFront**: $5-50/month
- **Total**: $110-390/month

### LLM Costs (Additional)

- **OpenAI GPT-4o-mini**: $0.15/1M input tokens, $0.60/1M output tokens
- **Groq (Free tier)**: 30 requests/min free
- **Google Gemini (Free tier)**: 60 requests/min free

---

## Support

For deployment issues:
- Check logs: `docker-compose logs -f`
- GitHub Issues: Create an issue in the repository
- Documentation: See README.md for additional details

---

**Last Updated**: 2025-12-22
**Deployment Version**: 2.0
